Das Lösen von Eigenwertproblemen ist eine Standarddisziplin in der
numerischen linearen Algebra. Gleichungen der Gestalt

\begin{equation}\label{eq:eigenproblem}
Ax = \lambda Bx
\end{equation}

begegnet man in ganz unterschiedlichen Kontexten. So sind sie beispielsweise
bei der Bestimmung von Eigenfrequenzen oder dem Ermitteln von Fixpunkten beim
Rotieren eines Fußballs\footnote{Hier wird auf den bekannten
\emph{Satz vom Fußball} angespielt. Dieser besagt, dass auf einem Fußball
zwei Punkte existieren, die zu Spielbeginn und zur Halbzeit
an der gleichen Stelle liegen -- informell formuliert.} ebenso wie beim
Untersuchen des PageRanks einer Website von
Bedeutung. Entsprechend strotz der Kanon von angebotenen numerischen
Lösungsmethoden von Vielfalt und Virtuosität.\\

Nun mag der Fall eintreten, da es notwendig wird, lediglich eine Teilmenge
aus der Menge aller Eigenpaare zu untersuchen.\\
\textcolor{red}{Geeignetes Beispiel finden.}\\

Wie soll nun aber der eifrige Numeriker die gewünschte Menge an Eigenpaaren
finden?\\

Man könnte zunächst versuchen sämtliche Eigenpaare zu berechnen, die das Problem
hergibt und händisch die gewünschte Teilmenge auswählen. Bei einem Problem
dieser Größenordnung dürfte der Rechenknecht allerdings eine ordentliche Weile
beschäftigt sein und das Leben ist fürwahr zu knapp, um auf das Terminieren
von Algorithmen zu warten.\\

Viel eleganter lässt sich dieses Problem mit einem Verfahren lösen, welches in
dem von \emph{Eric Polizzi} geschriebenen Paper \glqq Density-matrix-based
algorithm for solving eigenvalue problems\grqq\ \cite{polizzi} vorgestellt wird.
Speziell ist dieser mit \emph{FEAST} abgekürzte Algorithmus darauf ausgelegt,
Probleme der Art \eqref{eq:eigenproblem} für eine hermitesche Matrix $A$ und
eine hermitesche, positiv definite Matrix $B$ zu lösen.\footnote{Die Definitionen
dieser Begriffe werden im anschließenden Abschnitt wiederholt.}\\

Die vorliegende Arbeit wird die grundlegenden mathematischen Ideen dieses Algorithmus'
vorstellen. Es werden Möglichkeiten der Implementation präsentiert und neben
einer naiven Implementation in \emph{MATLAB} auch effizientere Umsetzungen
besprochen -- etwa vermöge der von \emph{Mario Berljafa} und \emph{Stefan G"uttel}
entwickelten \glqq\emph{Rational Krylov Toolbox for MATLAB}\grqq\ \cite{rkt}.



\section{Grundlagen}

Um das Lesen dieser Arbeit mehr zu einer Freude denn zu einer Schikane zu
machen, soll dieser Abschnitt einige Grundlagen der linearen Algebra und
der Funktionentheorie bereitstellen. Obschon sich der Autor bem"uht hat,
in der Literatur g"angige Notation zu benutzen, bittet er den
verst"andnissvollen Leser bei Unklarheiten im Anhang \glqq Notationen\grqq\
nachzuschlagen.\\

Den Anfang machen Definitionen und Resultaten aus der Matrizentheorie.
Eine Matrix $A\in\Cnn$ wird als \emph{hermitesch} bezeichnet, falls
sie die Identit"at $A=A^H$ erf"ullt. Sie ist \emph{positiv definit}, sofern
für alle Vektoren $x\in\Co$ die Abschätzung
\[
x^H A x > 0
\]
gilt. Folglich werden wir eine Matrix \emph{hermitesch positiv definit (HPD)}
nennen, wenn sie sowohl hermitesch als auch positiv definit ist.\\

Ist $A\in\Cnn$ eine solche HPD-Matrix und sind $x,y\in\Cn$, so werden wir anstelle von
$x^H A y$ die Notation $\sp{A}{x,y}$ verwenden. Im Falle $A=I_n$ schreiben wir
kurz $\sp{}{x,y}$. 
