Nachdem das vorangegangene Kapitel Ideen zum Filtern von Eigenpaaren theoretisch beleuchtet hat, werden wir uns nun mit der Frage der praktischen Umsetzbarkeit besch"aftigen.
Im Mittelpunkt wird dabei die Konstruktion geeigneter Suchr"aume stehen, welche im Rayleigh-Ritz-Verfahren zum Einsatz kommen sollen.
Es wird sich zeigen, dass die Konturintegration hierbei ein n"utzliches Hilfsmittel darstellt.

\section{Rayleigh-Ritz Iteration}\label{chap4:beschrr}

%Diese Erkenntnis ist aus algorithmischer Sicht h"ochst interessant. In seiner iterativen Variante kann das Rayleigh-Ritz Verfahren abgebrochen werden, sobald die Suchraumiterierte Wandelt man das Rayleigh-Ritz Verfahren der Art ab, dass

%Es wird sich zu einem sp"ateren Zeitpunkt herausstellen, dass diese Erkenntnis aus algorithmischer Sicht h"ochst n"utzlich ist.
%Die Rayleigh-Ritz-Methode l"asst sich n√§mlich in ein iteratives Verfahren umwandeln, welches in jedem Schritt den Suchraum "andert. Ist die Suchraumiterierte irgendwann einmal $A$-invariant, so kann der Algorithmus abgebrochen werden. \textcolor{red}{Krylow Raum...}\\

Bei der Behandlung des Rayleigh-Ritz Verfahrens wurde angedeutet, dass das Einbinden einer geeigneten Iterationsvorschrift dabei helfen kann, die G"ute von errechneten Ritz-Paaren zu verbessern.
Hierbei ist \glqq G"ute\grqq\ nat"urlich in Abh"angigkeit vom Kontext zu bewerten. Im Folgenden wollen wir uns genauer mit dieser omin"osen Interationsvorschrift auseinander setzen und beginnen die Herleitung bei einem sehr einfach umsetzbaren Verfahren zur Bestimmung von Eigenpaaren.\\

%\footnote{Um besser zu verstehen orienteiren wir uns bei der Einf"uhrung des Algs an der Dramaturgie von Saad blabla 115ff}

Ausgangspunkt f"ur unsere Betrachtungen ist ein gew"ohnliches Eigenwertproblem mit einer von Null verschiedenen hermiteschen Matrix $A\in\Cnn$. Bei der sogenannten \emph{Potenzmethode} wird
ausgehend von einem Startvektor $y_{(0)}\in\Co$ in jeder Iteration der Vektor
\[
y_{(k+1)} = \frac{1}{\|A^{k+1} y_{(0)}\|} A^{k+1}y_{(0)}
\]
oder dazu "aquivalent
\[
y_{(k+1)} = \frac{1}{\|Ay_{(k)}\|} Ay_{(k)}
\]
berechnet. Dieser Vorgang wird wiederholt, bis gewisse Abbruchkriterien erf"ullt sind. Man kann zeigen, dass die Folge der Iterierten gegen einen zum betragsm"a"sig gr"o"sten Eigenwert geh"orenden Eigenvektor konvergiert.\footnote{Ein Beweis hierzu ist im Anhang zu finden. Siehe Satz \ref{thm:appTheorems:Potenzmethode}.}
%, begn"ugen wir uns an dieser Stelle mit folgender Plausibilit"atsbetrachtung, welche in "ahnlicher Form in ~\cite[56]{stewart}
%zu finden ist.\\

%Seien $(\lambda_i, x_i)_{i=1:n}$ die Eigenpaare von $A$. Aufgrund der Hermitizit"at bilden dann die Eigenvektoren eine Basis des $\Cn$.
%Folglich existieren komplexwertige Skalare $\alpha_1,\ldots,\alpha_n$ mit
%\[
%y_{(0)} = \sum_{i=1}^n \alpha_i x_i.
%\]
%Wenden wir nun die $k$-te Potenz von $A$ auf $y_{(0)}$ an, ergibt sich daher wegen $A^k x_i = \lambda^k x_i$
%\begin{equation}\label{eq:chap3dominant}
%A^k y_{(0)} = \sum_{i=1}^n \alpha_i \lambda_i^k x_i.
%\end{equation}
%Wir wollen ohne Einschr"ankung annehmen, dass $|\lambda_1| \ge |\lambda_i|$ f"ur alle $i$ mit
%$1<i\le n$ gilt. Gegebenenfalls nummerieren wir die Eigenpaare und Skalare um. Dann wird f"ur gr"o"ser werdende $k$ die rechte Seite von \eqref{eq:chap3dominant} durch den Term $\alpha_1 \lambda_1^k x_1$ dominiert. In Kombination mit der Normierung f"uhrt dies letztlich
%zur behaupteten Approximierung.\footnote{Ein formaler Beweis ist im Anhang zu finden.}\\

\newpage
Da uns daran gelegen ist, nicht nur mit einzelnen Elementen des $\Cn$ zu arbeiten sondern mit Matrizen zu hantieren, m"ussen wir ein allgemeinere Form der Potenzmethode betrachten. Dazu w"ahlen diesmal eine Startmatrix $Y_{0}\in\C^{n,m}$ vollen Ranges und berechnen die $k$-te Iterierte mit
\[
Y_{(k)} = A^k Y_{(0)}.
\]
Bei der Normalisierung ist allerdings Vorsicht geboten: In seinen Abhandlungen "uber Unterraumiterationen
merkt Y. Saad in ~\cite[Abschnitt 5.1]{saad} an,
dass es beim ungeschickten Normalisieren vorkommen kann, dass die Spalten von $Y_{(k)}$ zunehmend ihre lineare Unabh"angigkeit verlieren.\footnote{Dies ist unmittelbar einzusehen, wenn man bedenkt, dass jede Spalte gegen einen dominanten Eigenvektor konvergiert.}\\

Anstatt jede Spalte von $Y_{(k)}$ separat zu normalisieren, wird eine QR-Zerlegung\footnote{Eine Formulierung des Satzes "uber die Existenz der QR-Zerlegung ist im Anhang zu finden. Siehe Satz \ref{thm:appTheorems:QR}. F"ur weitere Ausf"uhrungen siehe auch \cite[55 ff.]{stewart}.}
bem"uht. Diese f"uhrt in der Tat zu einer Normalisierung. Ist n"amlich $Y_{(k)} = QR$ mit
$Q = [q_i]_{i=1:m}$ die QR-Zerlegung, so gilt $\Bild(Y_{(k)}) = \Bild(Q)$ und $\|q_i\|_2 = 1$ f"ur $i=1:m$. Folglich stellt folgender Algorithmus eine Verallgemeinerung der Potenzmethode dar.

\begin{algorithm}
\caption{Verallgemeinerte Potenzmethode (Vgl. \cite[Algorithmus 5.1, 115]{saad})}\label{alg:chap4:potenzverfahrenMatrix}
\begin{algorithmic}[1]
\State W"ahle linear unabh"angige Vektoren $\{y_i\}_{i=1:m}$ und setze $Y_{(0)}\gets[y_i]_{i=1:m}$ und $k\gets 1$
\State \textbf{repeat}
\State \ \ \ \ Setze $Y_{(k)} \gets AY_{(k-1)}$ und berechne QR-Zerlegung $Y_{(k)} = QR$.
\State \ \ \ \ Setze $Y_{(k)} \gets Q$ und $k\gets k+1$.
\State \textbf{until} Verfahren konvergiert.
\end{algorithmic}
\end{algorithm}

Saad weist darauf hin, dass die Kosten der Berechnung der QR-Zerlegung sehr hoch werden k"onnen. Da der von den Spalten von $Y_{(k)}$ aufgespannte Unterraum gleich dem von den Spalten von $A^k Y_{(0)}$ aufgespannten Unterraum ist, schl"agt Saad daher folgende Abwandlung des eben vorgestellen Algorithmus' vor.

\begin{algorithm}
\caption{Gebrauch variabler Exponenten (Vgl. ~\cite[Algorithmus 5.2, 116]{saad})}\label{alg:chap4:potentePotenz}
\begin{algorithmic}[1]
\State W"ahle linear unabh"angige Vektoren $\{y_i\}_{i=1:m}$, setze $Y_\gets[y_i]_{i=1:m}$ und w"ahle initialen Exponenten $k$.
\State \textbf{repeat}
\State \ \ \ \ Setze $S \gets A^kY$ und orthonormalisiere $S$ zu $\widehat{S}$.
\State \ \ \ \ Setze $Y \gets \widehat{S}$.
\State \ \ \ \ W"ahle neuen Exponenten $k$.
\State \textbf{until} Verfahren konvergiert.
\end{algorithmic}
\end{algorithm}

Auch hier ist zu beachten, dass im Falle der Wahl eines sehr gro"sen Exponenten die Unabh"angigkeit der Spalten von $S$ nicht mehr gew"ahrleistet werden kann.
Wir wollen an dieser Stelle auf Konvergenz- und Laufzeitanalysen der eben vorgestellten Algorithmen verzichten und kommen schlie"slich zur vielfach angek"undigten Iterationsvorschrift, welche sich aus der Potenzmethode ableitet.

\newpage

\begin{algorithm}
\caption{Iteratives Rayleigh-Ritz Verfahren (Vgl. \cite[Algorithmus 5.3, 118]{saad})}\label{alg:chap4:rrIteration}
\begin{algorithmic}[1]
\State W"ahle linear unabh"angige Vektoren $\{y_i\}_{i=1:m}$, setze $Y_\gets[y_i]_{i=1:m}$ und w"ahle initialen Exponenten $k$.
\State \textbf{repeat}
\State \ \ \ \ Setze $S \gets A^k Y$.
\State \ \ \ \ Orthonormalisiere die Spalten von $S$ und setze $\widetilde{A} \gets S^H A S$.
\State \ \ \ \ Berechne Eigenvektoren $\widetilde{X} \gets [\widetilde{x}_i]_{i=1:m}$ von $\widetilde{A}$.
\State \ \ \ \ Setze $Y \gets S \widetilde{X}$.
\State \ \ \ \ W"ahle neuen Exponenten $k$.
\State \textbf{until} Verfahren konvergiert.
\end{algorithmic}
\end{algorithm}

Zun"achst ein Wort zur f"unften Zeile. Hier wurde das Berechnen von Schurvektoren -- so wie es in der oben zitierten Quelle vorgeschlagen wird -- durch das Berechnen von Eigenvektoren ersetzt. Dies ist m"oglich, weil $A$ nach Vereinbarung ein hermitesche Matrix ist und somit unit"ar diagonalisiert werden kann. Es ist daher nicht n"otig zwischen Eigenvektoren und Schurvektoren zu unterscheiden. Wie genau diese Eigenvektoren berechnet werden, wollen wir im Rahmen dieser Arbeit nicht genauer erl"autern.\\

Die Wurzeln des eben erarbeiteten Algorithmus' sind deutlich zu erkennen. In den Zeilen vier bis sechs wird das Rayleigh-Ritz Verfahren benutzt. Anstelle von Ritz-Paaren werden allerdings lediglich Ritz-Vektoren berechnet. In jeder Iteration wird wie beim Potenzverfahren ein neuer Exponent festgelegt und somit ein neuer Suchraum $\S = \Bild(A^k Y)$ vorgegeben. Erl"auterungen zum Konvergenzverhalten sind in \cite[Abschnitt 5]{saad} zu finden. Zur Berechnung von Eigenpaaren eines HPD-Eigenwertproblems $(A,B)$ bei dem $B$ nicht mehr der Identit"at entspricht, m"ussen die Zeilen vier bis sechs gem"a"s Algorithmus \ref{alg:chap3:grp} angepasst werden.\\

Es ist m"oglich, den zuletzt eingef"uhren Algorithmus weiter abzuwandeln. Dazu betrachten wir wieder ein HPD-Eigenwertproblem $(A,B)$. Zu diesem Duo gesellt sich nun mit $\p(B^{-1}A)$ ein Polynom in $B^{-1}A$, welches wir benutzen, um das iterative Rayleigh-Ritz Verfahren wie folgt zu "andern.

\begin{algorithm}
\caption{Beschleunigte Rayleigh-Ritz Iteration (Vgl. \cite[Algorithmus A]{ptep})}\label{alg:chap4:beschlRrIteration}
\begin{algorithmic}[1]
\State W"ahle $m$ linear unabh"angige Vektoren $Y_{(0)} \gets [y_i]_{i=1:m} \in\C^{n,m}$.
Setze $k \gets 1$.
\State \textbf{repeat}
\State \ \ \ \ Approximiere den Unterraumprojektor: $P_{(k)} \gets \p(B^{-1}A)Y_{(k-1)}$
\State \ \ \ \ Reduziere die Dimension: $\widetilde{A}_{(k)} \gets P_{(k)}^H A P_{(k)}$,
$\widetilde{B}_{(k)} \gets P_{(k)}^H B P_{(k)}$.
\State \ \ \ \ L"ose das transformierte Problem $\widetilde{A}_{(k)}\widetilde{X}_{(k)}
= \widetilde{B}_{(k)}\widetilde{X}_{(k)}\widetilde{\Lambda}_{(k)}$ in
$\widetilde{X}_{(k)}$ und $\widetilde{\Lambda}_{(k)}$.
\State \ \ \ \ Setze $Y_{(k)} \gets P_{(k)}\widetilde{X}_{(k)}$.
\State \ \ \ \ $k \gets k+1$.
\State \textbf{until} Abbruchkriterium ist erf"ullt.
\end{algorithmic}
\end{algorithm}

Diese Methode "ahnelt stark dem Algorithmus \ref{alg:chap4:rrIteration}. Die Zeilen vier bis sechs entsprechen erneut dem Rayleigh-Ritz Verfahren, aber die Berechnung des Suchraums $\S := \Bild(P_{(k)})$ geht anders vonstatten.

\newpage

Im Kontext dieses Algorithmus' wird $\p$ auch als \emph{Filter} oder \emph{Beschleuniger}
bezeichnet. Von dessen Wahl h"angt n"amlich ab, ob und wie gut Eigenpaare approximiert
werden: Sei $[\lambda_1,\lambda_2]$ ein reelles Intervall, auf dem $l\in\N$ Eigenwerte und die korrespondierenden Eigenvektoren gefunden werden k"onnen. Ist nun $\p(B^{-1}A)$ der Spektralprojektor,
$m=l$ und hat die Matrix $Y_{(1)} = \p(B^{-1}A) Y_{(0)}$ vollen Rang, so konvergiert der Algorithmus \ref{alg:chap4:beschlRrIteration} in einer Iteration
(Vgl. ~\cite[356]{ptep}).
Dies folgt unter Ausnutzung der Invarianz des Bildes von $P_{(1)}$ unter $B^{-1}A$
aus dem Satz $\ref{thm:chap3:invariant}$.\\

Da der Spektralprojektor in den meisten F"allen unbekannt sein d"urfte, liegt
die Idee nahe, ihn zu approximieren. Tang und Polizzi ~\cite[356]{ptep} merken an, dass dies gut funktioniert, falls $\p$ eine durch \emph{Gau"s-Legendre-Quadratur} konstruierte rationale Funktion ist.
Um den Gedankengang der Autoren nachvollziehen zu k"onnen, wird sich das folgende Intermezzo mit der Auffrischung des Konzeptes von Quadraturformeln und rationalen Funktionen besch"aftigen. Dabei sehen wir von Beweisen und ausufernden Erl"auterungen ab, da diese Thematik in den meisten Einf"uhrungsb"uchern zur numerischen Mathematik ausf"uhrlich besprochen wird.\footnote{Siehe zum Beispiel \cite[Abschnitt 6]{plato}} Im Anschluss fahren wir mit der
Konstruktion des Projektors fortfahren.

\section{Gau"s'sche Quadratur}

Um ein Integral numerisch zu approximieren, bedient man sich sogenannter \emph{Quadraturformeln}. Dazu betrachten wir eine stetige Funktion $f\colon\R\to\R$, welche wir auf einem gegebenen Intervall $I:=[a,b]\subset\R$ integrieren wollen.\footnote{Im Allgemeinen ist die Stetigkeit von $f$ nicht zwingend erforderlich. Wir werden uns hier der Einfachheit halber auf stetige Funktionen einschr"anken.}
Zu gegebenen St"utzpunkten $(x_i, f(x_i))_{i=0:n}$ auf $I\times\R$ sei $p_n$ das zugeh"orige \emph{Interpolationspolynom} vom Grad $n$, also ein Polynom, welches $p(x_i) = f(x_i)$ f"ur alle $i$ mit $0\le i\le n$ erf"ullt.\\

Dann bezeichnen wir die N"aherung
\begin{equation}\label{eq:quadratur}
Q_n(f) := \int_a^b p_n (x)\text{ d}x =
(b-a)\sum_{i=0}^n \omega_i f(x_i)
\end{equation}
als \emph{interpolatorische Quadraturformel}. Dabei gilt
\[
\omega_k = \int_0^1 \prod_{j=0,j\neq k}^n
\frac{t-t_j}{t_k - t_j} \text{ d}t, \ t_j
= \frac{x_j-a}{b-a}.
\]
Die Qualit"at der Approximation, also die Abweichung vom exakten Integral, h"angt ma"sgeblich von der Wahl und Anzahl der St"utzpunkte ab. Wollten wir
beispielsweise das Integral einer konstanten Funktion berechnen, so erschiene es wenig plausibel, anstelle der direkten Berechnung ein Polynom vom Grad 69 auf 70 St"utzstellen f"ur die Approximation zu bem"uhen.

\newpage

Bei der Anwendung von Gau"s-Legendre-Quadraturen ergibt sich die Wahl der St"utzpunkte durch die Berechnung von Nullstellen von Polynomen, die in einer Orthogonalit"atsbeziehung zueinander stehen.
Wir werden in K"urze formal formulieren, wie dies zu verstehen ist.\\

Ausgangspunkt f"ur die Integration ist nun eine stetige Funktion $f$, die eine Faktorisierung in zwei stetige Funktionen $g$ und $\omega$ der Art
\[
f = g\cdot \omega
\]
besitzt, wobei $\omega$ auf dem Integrationsintervall $[a,b]$ positiv sein soll. Die Funktion $\omega$ wird auch als \emph{Gewichtsfunktion} bezeichnet.
Ziel ist also nun die Berechnung von
\begin{equation}\label{eq:gintegral}
\int_a^b g(x)\omega(x) \text{ d}x,
\end{equation}
wobei wir zus"atzlich fordern, dass \eqref{eq:quadratur} und \eqref{eq:gintegral} f"ur alle Polynome bis zum Grad $(2n-1)$ "ubereinstimmen.\\

Dazu betrachten wir die Standardbasis $\{x^k\}_{k=0:(2n-1)}$ auf dem Raum der Polynome vom
Grad $(2n-1)$. Dann landen wir unweigerlich bei dem
Gleichungssystem
\[
\sum_{j=1}^n \omega_j x_j^k = \int_a^b x^k \omega(x) \text{ d}x \text{ mit } k = 0:2n-1.
\]
Man kann zeigen, dass die L"osung dieses Systems durch Nullstellen eines Polynoms gegeben ist, welches durch
ein Gram-Schmidt-Orthogonalisierungsverfahren bez"uglich des Skalarproduktes
\[
\langle p,q\rangle_\omega := \int_a^b p(t) q(t)\omega(t) \text{ d}t
\]
konstruiert wurde. Das hei"st konkret: Ausgehend vom Polynom $p_0 \equiv 1$ ist
\[
p_n(x) := x^n - \sum_{j=0}^{n-1} \frac{\langle x^n, p_j \rangle_\omega}{\langle p_j, p_j\rangle_\omega} p_j (x)
\]
gerade dasjenige Polynom, durch dessen Nullstellen das obige Gleichungssystem gel"ost wird. Sind nun
$\{x_j\}_{j=1:n}$ die Nullstellen dieses $n$-ten Orthogonalit"atspolynoms, so he"ist die numerische
Integrationsformel
\[
Q_n(f) = \sum_{j=1}^n \omega_j f(x_j) \text{ mit }
\omega_j = \langle L_j, 1 \rangle_\omega
= \int_a^b L_j(x)\p(x\text{ d}x
\]
\emph{Gau"s'sche Quadraturformel der $n$-ten Ordnung}.
%Dabei ist
\[
L_j(x) = \prod_{k\neq j=1}^n \frac{x-x_j}{x_k - x_j}.
\]

\newpage

\section{Approximation des Spektralprojektors}

Sei $(A,B)$ ein HPD-Eigenwertproblem und $I:=[\lambda_1, \lambda_2]$ ein reelles Intervall. Sei weiter $\mathcal{X}\subseteq\Cn$ derjenige Unterraum, welcher von den Eigenvektoren aufgespannt wird, die zu den im Inneren von $I$ befindlichen Eigenwerten korrespondieren. Wir wollen in diesem Abschnitt den Spektralprojektor approximieren, welcher den Vektorraum $\Cn$ auf $\mathcal{X}$ projeziert.\\

Die erste Ingredienz, die zum Gelingen dieser Approximation beitr"agt, ist eine rationale Funktion $\r\colon\C\to\C$ mit $\r(\R) \subseteq \R$, welche auf $I$ n"aherungsweise der Indikatorfunktion von $I$ entspricht.
Daf"ur bem"uhen wir die Cauchy'sche Integraldarstellung von der Indikatorfunktion und
wandeln diese mit Hilfe numerischer Quadraturformeln in die gew"unschte
rationale Funktion $\r$ um.\\

Zu"achst zur Indikatorfunktion: Ist $c$ der Mittelpunkt des Intervalls $I$ und
$r$ der Abstand des Mittelpunktes zum Rand des Intervalls, dann entspricht die Menge
\[
\mathcal{C} := \{z\in\C : |z-c| = r\}
\]
der Sph"are mit Radius $r$ um $c$. Mit dem Cauchy'schen Integralsatz
l"asst sich zeigen, dass im Falle $z\notin \mathcal{C}$
\[
\frac{1}{2\pi\iota}\int_{ \mathcal{C}}\frac{1}{\omega-z}\text{ d}\omega
= \begin{cases}1 &\text{ falls }|z-c| < r \\ 0 &\text{ falls }|z-c| > 0 \end{cases}
\]
gilt. Um dieses Integral mit einer Gau"s'schen Quadraturformel ann"ahern zu k"onnen, ben"otigen wir eine Parametrisierung von $\mathcal{C}$. Hierf"ur ziehen wir \cite{ptep} zurate und w"ahlen demzufolge
die Funktion
\[
\gamma\colon[-1,3]\to\C\text{, }
t\mapsto c+re^{\iota \frac{\pi}{2}(1+t)}
\]
als Parametrisierung der Sph"are $\mathcal{C}$.
%Die Ableitung von $\gamma$ ist dann f"ur jedes $t\in[-1,3]$ durch
%\[
%\gamma'(t)=\iota \frac{\pi}{2}re^{\iota \frac{\pi}{2}(1+t)}
%\]
%gegeben.
Wir erhalten dann f"ur alle $z\notin\mathcal{C}$ die Gleichung
\begin{align*}
\frac{1}{2\pi\iota}\int_{ \mathcal{C}}\frac{1}{\omega-z}\text{ d}\omega
&= \frac{1}{2\pi\iota} \int_{-1}^3 \frac{\gamma'(t)}{\gamma(t)-z}\text{ d}t \\
&= \frac{1}{2\pi\iota} \left( \int_{-1}^1 \frac{\gamma'(t)}{\gamma(t)-z} \text{ d}t +
\int_{1}^3\frac{\gamma'(t)}{\gamma(t)-z}\text{ d}t \right) \\
&= \frac{1}{2\pi\iota} \left( \int_{-1}^1 \frac{\gamma'(t)}{\gamma(t)-z} \text{ d}t +
\int_{-1}^1\frac{\gamma'(2-t)}{\gamma(2-t)-z}\text{ d}t \right) \\
&= \frac{1}{2\pi\iota} \int_{-1}^1 \left( \frac{\gamma'(t)}{\gamma(t)-z} +
\frac{\overline{\gamma'(t)}}{\overline{\gamma(t)}-z}\right)\text{d}t
\end{align*}
wobei $\overline{\gamma(t)}$ und $\overline{\gamma'(t)}$ die komplexen Konjugationen
von $\gamma(t)$ beziehungsweise $\gamma'(t)$ bezeichnen.

\newpage

Es seien nun $(w_j, t_j)_{j=1:m}$
die f"ur die Gau"s'sche Quadraturformel ben"otigten Gewichte und Diskretisierungspunkte.
Dann setzen wir
\[
\rho(z) := \frac{1}{2\pi\iota}\sum_{j=1}^m \left(
\frac{w_j \cdot \gamma'(t_j)}{\gamma(t_j)-z} - \frac{w_j \cdot \overline{\gamma'(t_j)}}{\overline{\gamma(t_j)}-z}
\right)
\]
und erhalten nach der Substitution $\gamma(t_j) := \gamma_j$ und
$\sigma_j := w_j \gamma'(t_j) / (2\pi\iota)$ die gew"unschte rationale
Funktion
\[
\r\colon\C\to\C, z\mapsto\sum_{j=1}^m\left(\frac{\sigma_j}{\gamma_j - z} +
\frac{\overline{\sigma_j}}{\overline{\gamma_j} - z}\right)
\]
zur Approximation der Indikatorfunktion. Hierbei ist bemerkenswert, dass die
rationale Funktion bereits in Partialbruchzerlegung vorliegt. Setzen wir schlie"slich $B^{-1}A$ in die
rationale Funktion ein, so erhalten wir
\begin{align*}
\r(B^{-1}A) &= \sum_{k=1}^m \sigma_k (\gamma_k I - B^{-1}A)^{-1} +
\sum_{k=1}^m \overline{\sigma_k} (\overline{\gamma_k} I - B^{-1}A)^{-1}\\
&= \sum_{k=1}^m \sigma_k (\gamma_k B - A)^{-1} B +
\sum_{k=1}^m \overline{\sigma_k} (\overline{\gamma_k} B - A)^{-1} B
\end{align*}
und folglich
\[
\r(B^{-1}A)Y =
\sum_{k=1}^q \sigma_k (\gamma_k B - A)^{-1} BV +
\sum_{k=1}^q \overline{\sigma_k} (\overline{\gamma_k} B - A)^{-1} BV
\]
f"ur eine Matrix $Y\in\C^{n,m}$.

\section{FEAST-Algorithmus}

Im Jahr 2009 stellte Eric Polizzi in \cite{polizzi} ein Verfahren vor, welches sich die Theorien der vorigen Abschnitte zu Nutze macht. Dieser \glqq[\ldots] \emph{fast and stable algorithm for solving the symmetric eigenvalue problem} [\ldots]\grqq\ \cite[Abstract]{polizzi} wurde seither weiterentwickelt und zahlreichen Analysen unterzogen.\footnote{Siehe etwa \cite{ptep},\cite{kpt} und \cite{lzp}.}
Wir wollen in diesem Abschnitt die wichtigen Punkte des oben zitierten Papers skizzieren und damit das vierte Kapitel abschlie"sen.\\


%Im dritten Kapitel wurde mit Satz \ref{thm:chap3:invariant} gezeigt, dass Ritz-Paare im Falle der $(B^{-1}A)$-Invarianz des Suchraumes $\S$ schon Eigenpaare sind. Wir k"onnten folglich die Iteration in Algorithmus \ref{alg:chap4:rrIteration} beenden, sobald eine Potenz
