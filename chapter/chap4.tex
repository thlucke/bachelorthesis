Nachdem das vorangegangene Kapitel Ideen zum Filtern von Eigenpaaren theoretisch beleuchtet hat, werden wir uns nun mit der Frage der praktischen Umsetzbarkeit besch"aftigen.
Im Mittelpunkt wird dabei die Konstruktion geeigneter Suchr"aume stehen, welche im Rayleigh-Ritz-Verfahren zum Einsatz kommen sollen.
Es wird sich zeigen, dass die Konturintegration hierbei ein n"utzliches Hilfsmittel darstellt.

\section{Beschleunigte Rayleigh-Ritz Iteration}\label{chap4:beschrr}

%Diese Erkenntnis ist aus algorithmischer Sicht h"ochst interessant. In seiner iterativen Variante kann das Rayleigh-Ritz Verfahren abgebrochen werden, sobald die Suchraumiterierte Wandelt man das Rayleigh-Ritz Verfahren der Art ab, dass

%Es wird sich zu einem sp"ateren Zeitpunkt herausstellen, dass diese Erkenntnis aus algorithmischer Sicht h"ochst n"utzlich ist.
%Die Rayleigh-Ritz-Methode l"asst sich n√§mlich in ein iteratives Verfahren umwandeln, welches in jedem Schritt den Suchraum "andert. Ist die Suchraumiterierte irgendwann einmal $A$-invariant, so kann der Algorithmus abgebrochen werden. \textcolor{red}{Krylow Raum...}\\

Bei der Behandlung des Rayleigh-Ritz Verfahrens wurde angedeutet, dass das Einbinden einer geeigneten Iterationsvorschrift dabei helfen kann, die G"ute von errechneten Ritz-Paaren zu verbessern.
Hierbei ist \glqq G"ute\grqq\ nat"urlich in Abh"angigkeit vom Kontext zu bewerten. Im Folgenden wollen wir uns genauer mit dieser omin"osen Interationsvorschrift auseinander setzen und beginnen die Herleitung bei einem sehr einfach umsetzbaren Verfahren zur Bestimmung von Eigenpaaren.\\

%\footnote{Um besser zu verstehen orienteiren wir uns bei der Einf"uhrung des Algs an der Dramaturgie von Saad blabla 115ff}

Ausgangspunkt f"ur unsere Betrachtungen ist ein gew"ohnliches Eigenwertproblem mit einer von Null verschiedenen hermiteschen Matrix $A\in\Cnn$. Bei der sogenannten \emph{Potenzmethode} wird
ausgehend von einem Startvektor $y_{(0)}\in\Co$ in jeder Iteration der Vektor
\[
y_{(k+1)} = \frac{1}{\|A^{k+1} y_{(0)}\|} A^{k+1}y_{(0)}
\]
oder dazu "aquivalent
\[
y_{(k+1)} = \frac{1}{\|Ay_{(k)}\|} Ay_{(k)}
\]
berechnet. Dieser Vorgang wird wiederholt, bis gewisse Abbruchkriterien erf"ullt sind. Man kann zeigen, dass die Folge der Iterierten gegen einen zum betragsm"a"sig gr"o"sten Eigenwert geh"orenden Eigenvektor konvergiert.\footnote{Ein Beweis hierzu ist im Anhang zu finden. Siehe Satz \ref{thm:appTheorems:Potenzmethode}.}
%, begn"ugen wir uns an dieser Stelle mit folgender Plausibilit"atsbetrachtung, welche in "ahnlicher Form in ~\cite[56]{stewart}
%zu finden ist.\\

%Seien $(\lambda_i, x_i)_{i=1:n}$ die Eigenpaare von $A$. Aufgrund der Hermitizit"at bilden dann die Eigenvektoren eine Basis des $\Cn$.
%Folglich existieren komplexwertige Skalare $\alpha_1,\ldots,\alpha_n$ mit
%\[
%y_{(0)} = \sum_{i=1}^n \alpha_i x_i.
%\]
%Wenden wir nun die $k$-te Potenz von $A$ auf $y_{(0)}$ an, ergibt sich daher wegen $A^k x_i = \lambda^k x_i$
%\begin{equation}\label{eq:chap3dominant}
%A^k y_{(0)} = \sum_{i=1}^n \alpha_i \lambda_i^k x_i.
%\end{equation}
%Wir wollen ohne Einschr"ankung annehmen, dass $|\lambda_1| \ge |\lambda_i|$ f"ur alle $i$ mit
%$1<i\le n$ gilt. Gegebenenfalls nummerieren wir die Eigenpaare und Skalare um. Dann wird f"ur gr"o"ser werdende $k$ die rechte Seite von \eqref{eq:chap3dominant} durch den Term $\alpha_1 \lambda_1^k x_1$ dominiert. In Kombination mit der Normierung f"uhrt dies letztlich
%zur behaupteten Approximierung.\footnote{Ein formaler Beweis ist im Anhang zu finden.}\\

\newpage
Da uns daran gelegen ist, nicht nur mit einzelnen Elementen des $\Cn$ zu arbeiten sondern mit Matrizen zu hantieren, m"ussen wir ein allgemeinere Form der Potenzmethode betrachten. Dazu w"ahlen diesmal eine Startmatrix $Y_{0}\in\C^{n,m}$ vollen Ranges und berechnen die $k$-te Iterierte mit
\[
Y_{(k)} = A^k Y_{(0)}.
\]
Bei der Normalisierung ist allerdings Vorsicht geboten: In seinen Abhandlungen "uber Unterraumiterationen
merkt Y. Saad in ~\cite[Abschnitt 5.1]{saad} an,
dass es beim ungeschickten Normalisieren vorkommen kann, dass die Spalten von $Y_{(k)}$ zunehmend ihre lineare Unabh"angigkeit verlieren.\footnote{Dies ist unmittelbar einzusehen, wenn man bedenkt, dass jede Spalte gegen einen dominanten Eigenvektor konvergiert.}\\

Anstatt jede Spalte von $Y_{(k)}$ separat zu normalisieren, wird eine QR-Zerlegung\footnote{Eine Formulierung des Satzes "uber die Existenz der QR-Zerlegung ist im Anhang zu finden. Siehe Satz \ref{thm:appTheorems:QR}. F"ur weitere Ausf"uhrungen siehe auch \cite[55 ff.]{stewart}.}
bem"uht. Diese f"uhrt in der Tat zu einer Normalisierung. Ist n"amlich $Y_{(k)} = QR$ mit
$Q = [q_i]_{i=1:m}$ die QR-Zerlegung, so gilt $\Bild(Y_{(k)}) = \Bild(Q)$ und $\|q_i\|_2 = 1$ f"ur $i=1:m$. Folglich stellt folgender Algorithmus eine Verallgemeinerung der Potenzmethode dar.

\begin{algorithm}
\caption{Verallgemeinerte Potenzmethode (Vgl. \cite[Algorithmus 5.1, 115]{saad})}\label{alg:chap4:potenzverfahrenMatrix}
\begin{algorithmic}[1]
\State W"ahle linear unabh"angige Vektoren $\{y_i\}_{i=1:m}$ und setze $Y_{(0)}\gets[y_i]_{i=1:m}$ und $k\gets 1$
\State \textbf{repeat}
\State \ \ \ \ Setze $Y_{(k)} \gets AY_{(k-1)}$ und berechne QR-Zerlegung $Y_{(k)} = QR$.
\State \ \ \ \ Setze $Y_{(k)} \gets Q$ und $k\gets k+1$.
\State \textbf{until} Verfahren konvergiert.
\end{algorithmic}
\end{algorithm}

Saad weist darauf hin, dass die Kosten der Berechnung der QR-Zerlegung sehr hoch werden k"onnen. Da der von den Spalten von $Y_{(k)}$ aufgespannte Unterraum gleich dem von den Spalten von $A^k Y_{(0)}$ aufgespannten Unterraum ist, schl"agt Saad daher folgende Abwandlung des eben vorgestellen Algorithmus' vor.

\begin{algorithm}
\caption{Gebrauch variabler Exponenten (Vgl. ~\cite[Algorithmus 5.2, 116]{saad})}\label{alg:chap4:potentePotenz}
\begin{algorithmic}[1]
\State W"ahle linear unabh"angige Vektoren $\{y_i\}_{i=1:m}$, setze $Y_\gets[y_i]_{i=1:m}$ und w"ahle initialen Exponenten $k$.
\State \textbf{repeat}
\State \ \ \ \ Setze $S \gets A^kY$ und orthonormalisiere $S$ zu $\widehat{S}$.
\State \ \ \ \ Setze $Y \gets \widehat{S}$.
\State \ \ \ \ W"ahle neuen Exponenten $k$.
\State \textbf{until} Verfahren konvergiert.
\end{algorithmic}
\end{algorithm}

Auch hier ist zu beachten, dass im Falle der Wahl eines sehr gro"sen Exponenten die Unabh"angigkeit der Spalten von $S$ nicht mehr gew"ahrleistet werden kann.
Wir wollen an dieser Stelle auf Konvergenz- und Laufzeitanalysen der eben vorgestellten Algorithmen verzichten und kommen schlie"slich zur vielfach angek"undigten Iterationsvorschrift, welche sich aus der Potenzmethode ableitet.

\newpage

\begin{algorithm}
\caption{Iteratives Rayleigh-Ritz Verfahren (Vgl. \cite[Algorithmus 5.3, 118]{saad})}\label{alg:chap4:rrIteration}
\begin{algorithmic}[1]
\State W"ahle linear unabh"angige Vektoren $\{y_i\}_{i=1:m}$, setze $Y_\gets[y_i]_{i=1:m}$ und w"ahle initialen Exponenten $k$.
\State \textbf{repeat}
\State \ \ \ \ Setze $S \gets A^k Y$.
\State \ \ \ \ Orthonormalisiere die Spalten von $S$ und setze $\widetilde{A} \gets S^H A S$.
\State \ \ \ \ Berechne Eigenvektoren $\widetilde{X} \gets [\widetilde{x}_i]_{i=1:m}$ von $\widetilde{A}$.
\State \ \ \ \ Setze $Y \gets S \widetilde{X}$.
\State \ \ \ \ W"ahle neuen Exponenten $k$.
\State \textbf{until} Verfahren konvergiert.
\end{algorithmic}
\end{algorithm}

Zun"achst ein Wort zur f"unften Zeile. Hier wurde das Berechnen von Schurvektoren -- so wie es in der oben zitierten Quelle vorgeschlagen wird -- durch das Berechnen von Eigenvektoren ersetzt. Dies ist m"oglich, weil $A$ nach Vereinbarung ein hermitesche Matrix ist und somit unit"ar diagonalisiert werden kann. Es ist daher nicht n"otig zwischen Eigenvektoren und Schurvektoren zu unterscheiden. Wie genau diese Eigenvektoren berechnet werden, wollen wir im Rahmen dieser Arbeit nicht genauer erl"autern.\\

Die Wurzeln des eben erarbeiteten Algorithmus' sind deutlich zu erkennen. In den Zeilen vier bis sechs wird das Rayleigh-Ritz Verfahren benutzt. Anstelle von Ritz-Paaren werden allerdings lediglich Ritz-Vektoren berechnet. In jeder Iteration wird wie beim Potenzverfahren ein neuer Exponent festgelegt und somit ein neuer Suchraum $\S = \Bild(A^k Y)$ vorgegeben. Erl"auterungen zum Konvergenzverhalten sind in \cite[Abschnitt 5]{saad} zu finden.


%Diese Methode l"asst sich nicht nur als direktes Verfahren implementieren, sondern ist auch iterativ umsetzbar. Doch wie genau geht diese Iteration vonstatten? Wor"uber wird iteriert?\\

%Die folgenden Abs"atze
%an den Ausf"uhrungen
%von Ping Tak Peter Tang und Eric Polizzi in ~\cite{ptep}. Allerdings wird
%die Notation im Sinne der Konsistenz dieser Arbeit an einigen Stellen abweichen.\\

%Betrachten wir zur Beantwortung dieser Fragen wie bisher das verallgemeinerte Eigenwertproblem mit zwei
%komplexwertigen, hermiteschen $(n\times n)$-Matrizen $A$ und $B$ und fordern
%zus"atzlich die positive Definitheit von $B$. Zu diesem Duo gesellt sich nun
%mit $\p(B^{-1}A)$ ein Polynom in $B^{-1}A$, welches wir benutzen, um den Algorithmus \ref{alg:grp} aus dem vorigen Kapitel gem"a"s dem
%oben zitierten Paper wie folgt zu "andern.

\begin{algorithm}
\caption{Beschleunigtes iteratives Rayleigh-Ritz-Verfahren}\label{alg:chap4:beschlRrIteration}
\begin{algorithmic}[1]
\State W"ahle $m$ linear unabh"angige Vektoren $Y_{(0)} \gets [y_i]_{i=1:m} \in\C^{n,m}$.
Setze $k \gets 1$.
\State \textbf{repeat}
\State \ \ \ \ Approximiere den Unterraumprojektor: $P_{(k)} \gets \p(B^{-1}A)Y_{(k-1)}$
\State \ \ \ \ Reduziere die Dimension: $\widetilde{A}_{(k)} \gets P_{(k)}^H A P_{(k)}$,
$\widetilde{B}_{(k)} \gets P_{(k)}^H B P_{(k)}$.
\State \ \ \ \ L"ose das transformierte Problem $\widetilde{A}_{(k)}\widetilde{X}_{(k)}
= \widetilde{B}_{(k)}\widetilde{X}_{(k)}\widetilde{\Lambda}_{(k)}$ in
$\widetilde{X}_{(k)}$ und $\widetilde{\Lambda}_{(k)}$.
\State \ \ \ \ Setze $Y_{(k)} \gets P_{(k)}\widetilde{X}_{(k)}$.
\State \ \ \ \ $k \gets k+1$.
\State \textbf{until} Abbruchkriterium ist erf"ullt.
\end{algorithmic}
\end{algorithm}



Die obigen Fragen sind also leicht beantwortet: In dieser Variante des Rayleigh-Ritz-Verfahrens wird solange "uber den Suchraum iteriert, bis die ermittelten Ritz-Paare gewisse Anforderungen erf"ullen.
Es dr"angt sich jedoch eine weitere Frage auf. Welche Funktion erf"ullt das Polynom $\p$?\\

Im Kontext dieses Algorithmus' wird $\p$ auch als \emph{Filter} oder \emph{Beschleuniger}
bezeichnet. Von dessen Wahl h"angt n"amlich ab, ob und wie gut Eigenpaare approximiert
werden: Sei $[\lambda_1,\lambda_2]$ ein reelles Intervall, auf dem $l\in\N$ Eigenwerte und die korrespondierenden Eigenvektoren gefunden werden k"onnen. Ist nun $\p(B^{-1}A)$ der Spektralprojektor,
$m=l$ und hat die Matrix $Q_{(1)} = \p(B^{-1}A) V_{(0)}$ vollen Rang, so konvergiert der Algorithmus \ref{alg:beschlrr} in einer Iteration
(Vgl. ~\cite[356]{ptep}).
Dies folgt unter Ausnutzung der Invarianz des Bildes von $Q_{(1)}$ unter $B^{-1}A$
aus dem Satz $\ref{thm:invariant}$.\\

Da der Spektralprojektor in den meisten F"allen unbekannt sein d"urfte, liegt
die Idee nahe, ihn wenigstens zu approximieren. Tang und Polizzi ~\cite[356]{ptep} merken an, dass dies gut funktioniert, falls $\p$ eine durch \emph{Gau"s-Legendre-Quadratur} konstruierte rationale Funktion ist.
Um den Gedankengang der Autoren nachvollziehen zu k"onnen, wird sich das folgende Intermezzo mit der Auffrischung des Konzeptes von Quadraturformeln und rationalen Funktionen besch"aftigen. Im Anschluss fahren wir mit der
Konstruktion des Projektors fortfahren.

\section{Gau"s'sche Quadratur}

Um ein Integral numerisch zu approximieren, bedient man sich sogenannter \emph{Quadraturformeln}. Dazu betrachten wir eine stetige Funktion $f\colon\R\to\R$, welche wir auf einem gegebenen Intervall $I:=[a,b]\subset\R$ integrieren wollen.\footnote{Im Allgemeinen ist die Stetigkeit von $f$ nicht zwingend erforderlich. Wir werden uns hier der Einfachheit halber auf stetige Funktionen einschr"anken.}
Zu gegebenen St"utzpunkten $(x_i, f(x_i))_{i=0:n}$ auf $I\times\R$ sei $p_n$ das zugeh"orige \emph{Interpolationspolynom} vom Grad $n$, also ein Polynom, welches $p(x_i) = f(x_i)$ f"ur alle $i$ mit $0\le i\le n$ erf"ullt.\\

Dann bezeichnen wir die N"aherung
\begin{equation}\label{eq:quadratur}
Q_n(f) := \int_a^b p_n (x)\text{ d}x =
(b-a)\sum_{i=0}^n \omega_i f(x_i)
\end{equation}
als \emph{interpolatorische Quadraturformel}. Dabei gilt
\[
\omega_k = \int_0^1 \prod_{j=0,j\neq k}^n
\frac{t-t_j}{t_k - t_j} \text{ d}t, \ t_j
= \frac{x_j-a}{b-a}.
\]
Die Qualit"at der Approximation, also die Abweichung vom exakten Integral, h"angt ma"sgeblich von der Wahl und Anzahl der St"utzpunkte ab. Wollten wir
beispielsweise das Integral einer konstanten Funktion berechnen, so erschiene es wenig plausibel, anstelle der direkten Berechnung ein Polynom vom Grad 69 auf 70 St"utzstellen f"ur die Approximation zu bem"uhen.\\

Bei der Anwendung von Gau"s-Legendre-Quadraturen ergibt sich die Wahl der St"utzpunkte durch die Berechnung von Nullstellen von Polynomen, die in einer Orthogonalit"atsbeziehung zueinander stehen.
Wir werden gleich formal formulieren, wie dies zu verstehen ist.\\

Ausgangspunkt f"ur die Integration ist nun eine stetige Funktion $f$, die eine Faktorisierung in zwei stetige Funktionen $g$ und $\omega$ der Art
\[
f = g\cdot \omega
\]
besitzt, wobei $\omega$ auf dem Integrationsintervall $[a,b]$ positiv sein soll.\footnote{Im unstetigen Fall darf die Funktion $\omega$ in h"ochstens endlich vielen Punkten negativ sein.} Ziel ist daher die Berechnung von
\begin{equation}\label{eq:gintegral}
\int_a^b g(x)\omega(x) \text{ d}x.
\end{equation}
Wir fordern nun, dass \eqref{eq:quadratur} mit \eqref{eq:gintegral} f"ur alle Polynome bis zum Grad $(2n-1)$ "ubereinstimmt.
Dazu betrachten wir die Standardbasis $\{x^i\}_{i=1:(2n-1)}$ auf dem Raum der Polynome vom
Grad $2n-1$. Dann landen wir unweigerlich bei dem
Gleichungssystem
\[
\sum_{j=1}^n \omega_j x_j^k = \int_a^b x^k \omega(x) \text{ d}x \text{ mit } k = 0,\ldots,2n-1.
\]
Man kann zeigen, dass die L"osung dieses Systems durch Nullstellen eines Polynoms gegeben ist, welches durch
ein Gram-Schmidt-Orthogonalisierungsverfahren bez"uglich des Skalarproduktes
\[
\langle p,q\rangle_\omega := \int_a^b p(t) q(t)\omega(t) \text{ d}t
\]
konstruiert wurde. Das hei"st konkret: Ausgehend vom Polynom $p_0 \equiv 1$ ist
\[
p_n(x) := x^n - \sum_{j=0}^{n-1} \frac{\langle x^n, p_j \rangle_\omega}{\langle p_j, p_j\rangle_\omega} p_j (x)
\]
gerade dasjenige Polynom, durch dessen Nullstellen das obige Gleichungssystem gel"ost wird. Sind nun
$x_1,\ldots,x_n$ die Nullstellen dieses $n$-ten Orthogonalit"atspolynoms, so he"ist die numerische
Integrationsformel
\[
Q_n(f) = \sum_{j=1}^n \omega_j f(x_j) \text{ mit }
\omega_j = \langle L_j, 1 \rangle_\omega
= \int_a^b L_j(x)\p(x\text{ d}x
\]
\emph{Gau"s'sche Quadraturformel der $n$-ten Ordnung}.
Dabei ist
\[
L_j(x) = \prod_{k\neq j=1}^n \frac{x-x_j}{x_k - x_j}.
\]

\section{Approximation des Spektralprojektors}

Nachdem wir diese Kurzzusammenfassung des Gau"s-Quadratur-Verfahrens diskutiert haben,
widmen wir uns wieder der Approximation des Spektralprojektors
$P = X_k X_k^H B$. Dabei "ubernehmen wir die am Anfang dieses Kapitels eingef"uhrte Notation, sowie die an die Matrizen $A$ und $B$ gestellten Voraussetzungen.\\

Wenden wir uns daher wieder dem reellen Intervall $I := [\lambda_1, \lambda_2]$ zu. Das Ziel ist
die Konstruktion einer rationalen Funktion $\r\colon\C\to\C$ mit $\r(\R) \subseteq \R$,
die auf $I$ n"aherungsweise der Indikatorfunktion von $I$ entspricht. Dazu
bem"uhen wir die Cauchy'sche Integraldarstellung der Indikatorfunktion und
wandeln diese mit Hilfe numerischer Quadraturformeln in die gew"unschte
rationale Funktion $\r$ um.\\

Zu"achst zur Indikatorfunktion: Ist $c\in\R$ der Mittelpunkt des Intervalls $I$ und
$r$ der Abstand des Mittelpunktes zum Rand des Intervalls, dann entspricht die Menge
\[
\mathcal{C} := \{z\in\C : |z-c| = r\}
\]
gerade einer Sph"are mit Radius $r$ um $c$. Mit dem Cauchy'schen Integralsatz
l"asst sich zeigen, dass im Falle $z\notin \mathcal{C}$
\[
\frac{1}{2\pi\iota}\int_{ \mathcal{C}}\frac{1}{\omega-z}\text{ d}\omega
= \begin{cases}1 &\text{ falls }|z-c| < r \\ 0 &\text{ falls }|z-c| > 0 \end{cases}
\]
gilt. Dieses Integral gilt es nun zu approximieren.\textcolor{red}{wie genau?}(Vgl. ~\cite[20]{jaenich}).\\

Wir werden das eben diskutierte Integral mit einer Gau"s-Legendre Quadraturformel ann"ahern.
Dazu ist es n"otig die Kontur $\mathcal{C}$ so zu parametrisieren, dass eine Transformation
der Integrationsgrenzen auf das Intervall $[-1,1]$ m"oglichst einfach m"oglich ist. Zu diesem Zweck sei
\begin{align*}
\gamma\colon[-1,3]&\to\C \\
t&\mapsto c+re^{\iota \frac{\pi}{2}(1+t)}
\end{align*}
als Parametrisierung der Sph"are gew"ahlt. Die
Ableitung von $\gamma$ ist dann f"ur jedes $t\in[-1,3]$ durch
\[
\gamma'(t)=\iota \frac{\pi}{2}re^{\iota \frac{\pi}{2}(1+t)}
\]
gegeben. Mit den bekannten Regeln der Integration erhalten wir somit f"ur alle $z\notin\mathcal{C}$
\begin{align*}
\frac{1}{2\pi\iota}\int_{ \mathcal{C}}\frac{1}{\omega-z}\text{ d}\omega
&= \frac{1}{2\pi\iota} \int_{-1}^3 \frac{\gamma'(t)}{\gamma(t)-z}\text{ d}t \\
&= \frac{1}{2\pi\iota} \left( \int_{-1}^1 \frac{\gamma'(t)}{\gamma(t)-z} \text{ d}t +
\int_{1}^3\frac{\gamma'(t)}{\gamma(t)-z}\text{ d}t \right) \\
&= \frac{1}{2\pi\iota} \left( \int_{-1}^1 \frac{\gamma'(t)}{\gamma(t)-z} \text{ d}t +
\int_{-1}^1\frac{\gamma'(2-t)}{\gamma(2-t)-z}\text{ d}t \right) \\
&= \frac{1}{2\pi\iota} \int_{-1}^1 \left( \frac{\gamma'(t)}{\gamma(t)-z} +
\frac{\overline{\gamma'(t)}}{\overline{\gamma(t)}-z}\right)\text{d}t
\end{align*}
wobei $\overline{\gamma(t)}$ und $\overline{\gamma'(t)}$ die komplexen Konjugationen
von $\gamma(t)$ beziehungsweise $\gamma'(t)$ bezeichnen.\\

F"ur $q\in\N$ mit \textcolor{red}{wie gro"s ist $q$ genau?} seien $(w_j, t_j)_{j=1:q}$
die f"ur die Gau"s-Legendre-Quadratur ben"otigten Gewichte und Diskretisierungspunkte.
Dann setzen wir
\[
\rho(z) := \frac{1}{2\pi\iota}\sum_{j=1}^q \left(
\frac{w_j \cdot \gamma'(t_j)}{\gamma(t_j)-z} - \frac{w_j \cdot \overline{\gamma'(t_j)}}{\overline{\gamma(t_j)}-z}
\right)
\]
und erhalten nach der Substitution $\gamma(t_j) := \gamma_j$ und
$\sigma_j := w_j \gamma'(t_j) / (2\pi\iota)$ die gew"unschte rationale
Funktion
\[
\r\colon\C\to\C, z\mapsto\sum_{j=1}^q\left(\frac{\sigma_j}{\gamma_j - z} +
\frac{\overline{\sigma_j}}{\overline{\gamma_j} - z}\right)
\]
zur Approximation der Indikatorfunktion. Hierbei ist bemerkenswert, dass die
rationale Funktion bereits in Partialbruchzerlegung vorliegt. Setzen wir schlie"slich $B^{-1}A$ in die
rationale Funktion ein, so erhalten wir
\begin{align*}
\r(B^{-1}A) &= \sum_{k=1}^q \sigma_k (\gamma_k I - B^{-1}A)^{-1} +
\sum_{k=1}^q \overline{\sigma_k} (\overline{\gamma_k} I - B^{-1}A)^{-1}\\
&= \sum_{k=1}^q \sigma_k (\gamma_k B - A)^{-1} B +
\sum_{k=1}^q \overline{\sigma_k} (\overline{\gamma_k} B - A)^{-1} B
\end{align*}
und folglich
\[
\r(B^{-1}A)V =
\sum_{k=1}^q \sigma_k (\gamma_k B - A)^{-1} BV +
\sum_{k=1}^q \overline{\sigma_k} (\overline{\gamma_k} B - A)^{-1} BV
\]
f"ur eine Matrix $V\in\C^{n,q}$.

%Ausgehend von zwei Polynomen $p, q\in\C [t]$ mit
%\[
%p := \sum_{k=0}^n p_k t^k \text{ \ und\ } q := \sum_{k=0}^n q_k t^k
%\]
%definieren wir eine rationale Funktion $\rho\colon\C\setminus{N_q}\to\C$ verm"oge
%\[
%\r(t) := \frac{p(t)}{q(t)}
%\]
%und identifizieren wie "ublich die Unbestimmte $t$ mit den Argumenten von $p$ und $q$.
%Dabei ist $N_q := \{t\in\C \mid q(t) = 0\}$.
%\section{Der FEAST-Algorithmus}

%f"urderhin
